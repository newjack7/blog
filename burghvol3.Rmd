---
title: "Burghersh vol 3"
author: "Jack Newman"
date: "25/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
#Load the packages for spacy parsing
library(lubridate)
library(tidygeocoder)
library(tif)
library(reticulate)
library(spacyr)

```

Import and format the data

```{r}
#import from csv
burghershRegisterVol3 <- read_csv("Lincolnshire csv Data/burghersh register vol 3.csv")
#extract strings which are a digit followed immediately but a full stop.
burghershVol3Filter <- burghershRegisterVol3 %>% mutate(ID1 = (str_extract(ID, "[\\d]+\\.")))
#filter out the NAs
burghershVol3Filter <- burghershVol3Filter %>% filter(!is.na(ID1))
#Select the correct columns
burghershVol3Filter <- burghershVol3Filter %>% select(ID1, text)
#remove the last character from column ID1 (full stops)
burghershVol3Filter$ID1 = substr(burghershVol3Filter$ID1,1,nchar(burghershVol3Filter$ID1)-1)
#check to see if any entries are missing or duplicated (should return 0)
setdiff(1:5007, burghershVol3Filter$ID1)
#Turn ID1 column into a sortable numeric column
burghershVol3Filter <- transform(burghershVol3Filter, ID1 = as.numeric(ID1))


```

```{r}
#Would prefer the large but it takes too long
spacy_initialize(model = "en_core_web_trf")
```

```{r}
#Create the TIF (Text Interchange Format) data structure which spacy needs as an input

burghVol3TIF <- data.frame(doc_id = burghershVol3Filter$ID1, text = burghershVol3Filter$text)

#Check if the format is correct
tif_is_corpus_df(burghVol3TIF)
#This always seems to say FALSE but it still works in spacy?

#Parse the text through Spacy (takes too long and is unecessary at this point)
  #burghVol3parsed <- spacy_parse(burghVol3TIF, lemma = FALSE, entity = TRUE, nounphrase = TRUE)

#This has to use the small spacy model as it takes too long otherwise
burghVol3parsed <- spacy_extract_entity(burghVol3TIF)

slice(burghVol3parsed, 500:510)

```

```{r}
#Re-unite the entities  - not needed as I used spacy_extract_entity which consolidates entities already
  #burghConsolidate <- burghVol3parsed %>% entity_consolidate()

#Filter for locations - includes organisations as I want to capture 'university of oxford' as well
vol3Places <- burghVol3parsed %>% filter(ent_type == "GPE" | ent_type == "ORG")
#count locations 
vol3PlacesCount <-vol3Places  %>% count(text, sort = TRUE)
#filter out some mistakes
vol3PlacesCount<- vol3PlacesCount %>% mutate(country = "United Kingdom") %>% rename(city = text)
vol3Geo <- vol3PlacesCount %>% geocode(city = city, country = country, method = 'osm')

write.csv(vol3Geo, file = "vol3Geo.csv")

```

