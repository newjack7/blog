lincsTopics <- tidy(lincsLDA, matrix = "beta")
lincsTopics
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
#I write the result to CSV so I can read it more easily
write.csv(topics, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topics.csv")
library(readr)
lincsOCR <- read_csv("Lincolnshire csv Data/lincsOCR.csv")
View(lincsOCR)
#Filters out all non 'Event' data
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
#Tokenizes the text
lincsTokens <- lincsEvents %>% unnest_tokens(word, 'QUOTE_TRANSCRIPTION')
#Unstopped plot
lincsTokens %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Removing 'stop words'
lincsStopped <- lincsTokens %>% anti_join(stop_words)
#Data with stop words removed and plot >200
lincsStopped %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Create a list of Personal names from the original data
lincsPeople <- filter(lincsOCR, TYPE == "PERSON")
#Select desired columns from original text
lincsStopPeople <- lincsPeople %>% select(QUOTE_TRANSCRIPTION, TYPE)
#Unnest Tokens
lincsStopPeople <- lincsStopPeople %>% unnest_tokens(word, QUOTE_TRANSCRIPTION)
#Removing Personal name using anti_join()
lincsPeopleStopped <- lincsStopped %>% anti_join(lincs_stop_people)
#Create a list of Personal names from the original data
lincsPeople <- filter(lincsOCR, TYPE == "PERSON")
#Select desired columns from original text
lincsStopPeople <- lincsPeople %>% select(QUOTE_TRANSCRIPTION, TYPE)
#Unnest Tokens
lincsStopPeople <- lincsStopPeople %>% unnest_tokens(word, QUOTE_TRANSCRIPTION)
#Removing Personal name using anti_join()
lincsPeopleStopped <- lincsStopped %>% anti_join(lincsStopPeople)
#Plot with personal names removed and >150 occurences
lincsPeopleStopped %>% count(word, sort = TRUE) %>% filter(n > 100) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip()+ theme_minimal()
# This removes the digits
lincsDigitStopped <- lincsPeopleStopped %>% filter(grepl('^\\D', word))
#This re-runs the plot filtered to only include words which occur 75 times or more.
lincsDigitStopped %>% count(word, sort = TRUE) %>% filter(n > 75) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#inner_join to find months from the data and return to a new data frame called monthsCount
monthsCount <- inner_join(lincsTokens, months)
#inner_join to find months from the data and return to a new data frame called monthsCount
monthsCount <- inner_join(lincsTokens, months)
#Plot of months
monthsCount %>% count(word) %>% ggplot(aes(x = factor(word, level = monthsReversed), y = n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsDTM <- lincsEvents %>% select(word, lincsID, UUID)
View(lincsEvents)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(str_extract('^w'))
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(str_extract(QUOTE_TRANSCRIPTION, '^w'))
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^w')))
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^w')))
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^w+')))
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w')))
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
lincsEvents <- lincsEvents %>% rename(allegation = word)
lincsEvents <- lincsEvents %>% rename(allegation = QUOTE_TRANSCRIPTION)
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(allegation, '^\\d+', "")))
lincsDTM <- lincsEvents %>% select(allegation, lincsID, UUID)
lincsDTM <- lincsDTM %>% unnest_tokens(allegation, allegation)
lincsDTM <- lincsDTM %>%
count(allegation, lincsID) %>%
cast_dtm(allegation, lincsID, n)
lincsLDA <- LDA(lincsDTM, k = 10, control = list(seed = 1234))
lincsTopics <- tidy(lincsLDA, matrix = "beta")
lincsTopics
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
#I write the result to CSV so I can read it more easily
write.csv(topics, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topics.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
lincsTopics <- tidy(lincsLDA, matrix = "beta")
lincsTopics
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
#I write the result to CSV so I can read it more easily
write.csv(topics, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topics.csv")
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w')))
lincsEvents <- lincsEvents %>% rename(allegation = QUOTE_TRANSCRIPTION)
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(allegation, '^\\d+', "")))
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w')))
lincsEvents <- lincsEvents %>% rename(allegation = QUOTE_TRANSCRIPTION)
lincsEvents <- lincsEvents %>% mutate(allegation = (str_replace(allegation, '^\\d+', "")))
lincsDTM <- lincsEvents %>% select(allegation, lincsID, UUID)
View(lincsDTM)
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
lincsEvents <- lincsEvents %>% rename(allegation = QUOTE_TRANSCRIPTION)
lincsEvents <- lincsEvents %>% mutate(allegation = (str_replace(allegation, '^\\d+', "")))
lincsDTM <- lincsEvents %>% select(allegation, lincsID, UUID)
lincsDTM <- lincsDTM %>% unnest_tokens(word(), allegation)
lincsDTM <- lincsEvents %>% select(allegation, lincsID, UUID)
lincsDTM <- lincsDTM %>% unnest_tokens(word, allegation)
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
lincsEvents <- lincsEvents %>% rename(allegation = QUOTE_TRANSCRIPTION)
lincsEvents <- lincsEvents %>% mutate(allegation = (str_replace(allegation, '^\\d+', "")))
lincsDTM <- lincsEvents %>% select(allegation, lincsID, UUID)
lincsDTM <- lincsDTM %>% unnest_tokens(allegation, allegation)
lincsDTM <- lincsDTM %>%
count(allegation, lincsID) %>%
cast_dtm(allegation, lincsID, n)
lincsLDA <- LDA(lincsDTM, k = 10, control = list(seed = 1234))
#Filters out all non 'Event' data
Lincolnshire_Text <- filter(LincolnshireOCR, TYPE == 'EVENT')
#Filters out all non 'Event' data
Lincolnshire_Text <- filter(LincsOCR, TYPE == 'EVENT')
library(readr)
lincsOCR <- read_csv("Lincolnshire csv Data/lincsOCR.csv")
View(lincsOCR)
LincsEventsTokens %>% unnest_tokens(word, 'QUOTE_TRANSCRIPTION')
LincsEventsTokens <- lincsEvents %>% unnest_tokens(word, 'QUOTE_TRANSCRIPTION')
LincsEventsTokens <- lincsEvents %>% unnest_tokens(allegation, allegation)
lincsEventsTokens <- lincsEvents %>% unnest_tokens(allegation, allegation)
lincsEventsTokens %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
lincsEventsTokens %>% count(allegation, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
lincsEventsTokens %>% count(allegation, sort = TRUE) %>% filter(n > 200) %>% mutate(allegation = reorder(allegation, n)) %>% ggplot(aes(allegation, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Removing 'stop words'
lincsStopped <- lincsEventsTokens %>% anti_join(stop_words)
stop_words
#Removing 'stop words'
lincsStopped <- lincsEventsTokens %>% anti_join(stop_words, by word = allegation)
#Removing 'stop words'
lincsStopped <- lincsEventsTokens %>% anti_join(stop_words, by = allegation,word)
#rename `allegation` to `word` for anti_join
lincsTokens <- lincsTokens %>% rename(word = allegation)
#rename `allegation` to `word` for anti_join
lincsEventsTokens <- lincsEventsTokens %>% rename(word = allegation)
#Removing 'stop words'
lincsStopped <- lincsEventsTokens %>% anti_join(stop_words)
#Data with stop words removed and plot >200
lincsStopped %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Create a list of Personal names from the original data
lincs_people <- filter(LincolnshireOCR, TYPE == "PERSON")
#Create a list of Personal names from the original data
lincs_people <- filter(LincsOCR, TYPE == "PERSON")
#Create a list of Personal names from the original data
lincs_people <- filter(lincsOCR, TYPE == "PERSON")
#Select desired columns from original text
lincs_stop_people <- lincs_people %>% select(QUOTE_TRANSCRIPTION, TYPE)
#Unnest Tokens
lincs_stop_people <- lincs_stop_people %>% unnest_tokens(word, QUOTE_TRANSCRIPTION)
#Removing Personal name using anti_join()
lincs_people_stopped <- Lincolnshire_Stopped %>% anti_join(lincs_stop_people)
#Removing Personal name using anti_join()
lincs_people_stopped <- lincsStopped %>% anti_join(lincs_stop_people)
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
#rename column to allegation for future analysis
lincsEvents <- lincsEvents %>% rename(word = QUOTE_TRANSCRIPTION)
#Delete the first digit from the allegation column. This removes McLane's index.
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
#Create lincsDTM from lincsEvents
lincsDTM <- lincsEvents %>% select(word, lincsID, UUID)
#Filter for stop words
lincsDTM <- lincsDTM %>% anti_join(stop_words)
#filter for digits
lincsDTM <- lincsDTM %>% filter(grepl('^\\D', word))
lincsDTM <- lincsDTM %>% unnest_tokens(word, word)
lincsDTM <- lincsDTM %>%
count(word, lincsID) %>%
cast_dtm(word, lincsID, n)
lincsLDA <- LDA(lincsDTM, k = 10, control = list(seed = 1234))
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
#rename column to allegation for future analysis
lincsEvents <- lincsEvents %>% rename(word = QUOTE_TRANSCRIPTION)
#Delete the first digit from the allegation column. This removes McLane's index.
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
#Create lincsDTM from lincsEvents
lincsDTM <- lincsEvents %>% select(word, lincsID, UUID)
#Un-nest the tokens
lincsDTM <- lincsDTM %>% unnest_tokens(word, word)
#Filter for stop words
lincsDTM <- lincsDTM %>% anti_join(stop_words)
#filter for digits
lincsDTM <- lincsDTM %>% filter(grepl('^\\D', word))
lincsDTM %>% count(word, sort = TRUE)
#Removing Personal name using anti_join()
lincsDTM <- lincsDTM %>% anti_join(lincs_stop_people)
lincsDTM %>% count(word, sort = TRUE)
View(lincsDTM)
lincsDTM %>% count(word, sort = TRUE) %>% filter(n > 100) %>% mutate(word = reorder(word,n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip()+ theme_minimal()
View(lincsOCR)
source('~/GitHub/blog/Data processing.R', echo=TRUE)
View(lincsPlacesStopped)
View(lincsTokens)
View(lincsStopped)
View(lincsEventsTokens)
#un-nest lincsEvents
lincsEventsTokens <- lincsEvents %>% unnest_tokens(word, word)
View(lincsEventsTokens)
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
library(readr)
lincsOCR <- read_csv("Lincolnshire csv Data/lincsOCR.csv")
View(lincsOCR)
#Create `lincsEvents`
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%   select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
View(lincsEvents)
#rename column to allegation for future analysis
lincsEvents <- lincsEvents %>% rename(word = QUOTE_TRANSCRIPTION)
#Delete the first digit from the allegation column. This removes McLane's index.
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
#un-nest lincsEvents
lincsEventsTokens <- lincsEvents %>% unnest_tokens(word, word)
View(lincsEventsTokens)
#Filter for stop words
lincsStopped <- lincsEventsTokens %>% anti_join(stop_words)
#filter for digits
lincsNoDigit<- lincsEventsTokens %>% filter(grepl('^\\D', word))
#Create a list of Personal names from the original data
lincsPeople <- filter(lincsOCR, TYPE == "PERSON")
#Select desired columns from original text
#lincsPeople <- lincsPeople %>% select(QUOTE_TRANSCRIPTION, TYPE, UUID)
#Unnest Tokens
lincsPeople <- lincsPeople %>% unnest_tokens(word, QUOTE_TRANSCRIPTION)
#Removing Personal name using anti_join()
lincsPeopleStopped <- lincsEventsTokens %>% anti_join(lincs_stop_people)
#Removing Personal name using anti_join()
lincsPeopleStopped <- lincsEventsTokens %>% anti_join(lincsPeople)
View(lincsPeople)
View(lincsPeopleStopped)
#Removing Personal name using anti_join()
lincsPeopleStopped <- lincsEventsTokens %>% anti_join(lincsPeople, by = word)
#Removing Personal name using anti_join()
lincsPeopleStopped <- lincsEventsTokens %>% anti_join(lincsPeople, by = 'word')
#Creatng a set of place names from the text and removing them
lincsPlaces <- filter(lincsOCR, TYPE == "PLACE")
#Select desired columns from original text
#lincsPlaces <- lincsPlaces %>% select(QUOTE_TRANSCRIPTION, TYPE, UUID)
#Unnest Tokens
lincsPlaces <- lincsPlaces %>% unnest_tokens(word, QUOTE_TRANSCRIPTION)
#Removing Personal name using anti_join()
lincsPlacesStopped <- lincsEvents %>% anti_join(lincsPlaces, by = 'word')
View(lincsPlacesStopped)
#Removing Personal name using anti_join()
lincsPlacesStopped <- lincsPlaces %>% anti_join(lincsPlaces, by = 'word')
#Removing Personal name using anti_join()
lincsPlacesStopped <- lincsEventsTokens %>% anti_join(lincsPlaces, by = 'word')
lincsTotalTidy <- lincsTotalTidy %>% filter(grepl('^\\D', word))
#Join tables to a single dataframe with no digits, places, or people
lincsTotalTidy <- lincsEventsTokens %>% anti_join(stop_words)
View(lincsTotalTidy)
lincsTotalTidy <- lincsTotalTidy %>% filter(grepl('^\\D', word))
lincsTotalTidy <- lincsTotalTidy %>% anti_join(lincsPeople, by = 'word')
lincsTotalTidy <- lincsTotalTidy %>% anti_join(lincsPlaces, by = 'word')
#Join tables to a single dataframe with no digits, places, or people
lincsTotalTidy <- lincsEventsTokens %>% anti_join(stop_words)
lincsTotalTidy <- lincsTotalTidy %>% filter(grepl('^\\D', word))
lincsTotalTidy <- lincsTotalTidy %>% anti_join(lincsPeople, by = 'word')
lincsTotalTidy <- lincsTotalTidy %>% anti_join(lincsPlaces, by = 'word')
lincsDTM <- lincsTotalTidy %>%
select(word, lincsID) %>%
count(word, lincsID) %>%
cast_dtm(word, lincsID, n)
lincsTotalTidy <- LDA(lincsDTM, k = 10, control = list(seed = 1234))
#Join tables to a single dataframe with no digits, places, or people
lincsTotalTidy <- lincsEventsTokens %>% anti_join(stop_words)
lincsTotalTidy <- lincsTotalTidy %>% filter(grepl('^\\D', word))
lincsTotalTidy <- lincsTotalTidy %>% anti_join(lincsPeople, by = 'word')
lincsTotalTidy <- lincsTotalTidy %>% anti_join(lincsPlaces, by = 'word')
lincsDTM <- lincsTotalTidy %>%
select(word, lincsID) %>%
count(word, lincsID) %>%
cast_dtm(word, lincsID, n)
lincsDTM <- LDA(lincsDTM, k = 10, control = list(seed = 1234))
lincsTopics <- tidy(lincsLDA, matrix = "beta")
lincsDTM <- lincsTotalTidy %>%
select(word, lincsID) %>%
count(word, lincsID) %>%
cast_dtm(word, lincsID, n)
lincsLDA <- LDA(lincsDTM, k = 10, control = list(seed = 1234))
lincsTopics <- tidy(lincsLDA, matrix = "beta")
lincsTopics
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
#I write the result to CSV so I can read it more easily
write.csv(topics, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topics.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
#I write the result to CSV so I can read it more easily
write.csv(topics, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topics.csv")
View(lincs_top_terms)
topics <- lincs_top_terms %>%  inner_join(lincsEvents)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
View(topics)
topics %>% count(topic, sort = TRUE)
lincs_top_terms %>% count(topic, sort = TRUE)
topics <- lincsEvents %>%  left_join(lincs_top_terms)
View(topics)
topics <- lincs_top_terms %>%  left_join(lincsEvents)
topics %>% count(topic, sort = TRUE)
topics <- lincsEvents %>%  semi_join(lincs_top_terms)
topics %>% count(topic, sort = TRUE)
View(topics)
topics <- inner_join(lincs_top_terms, lincsEvents)
#I am doing something wrong with the join so it is duplicating everything
topics <-  topics[!duplicated(topics$lincsID), ]
View(topics)
topics %>% count(topic, sort = TRUE)
topics <- inner_join(lincs_top_terms, lincsEvents)
lincs_top_terms <- lincs_top_terms %>% rename(lincsID = term)
#I write the result to CSV so I can read it more easily
write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topterms.csv")
#Create Dataframes for each topic
topicOne <- lincs_top_terms %>% filter(topic == 1)
View(topicOne)
#Now I want to join all of these to the allegations so I can read them easily in one place
topicOne <- topicOne %>% inner_join(lincsEvents)
topicOne <-  topicOne[!duplicated(topicOne$lincsID), ]
topicTwo <- topicTwo %>% inner_join(lincsEvents)
topicTwo <- lincs_top_terms %>% filter(topic == 2)
View(topicTwo)
topicTwo <- topicTwo %>% inner_join(lincsEvents)
topicTwo <-  topicTwo[!duplicated(topicTwo$lincsID), ]
topicThree <- lincs_top_terms %>% filter(topic == 3)
topicFour <- lincs_top_terms %>% filter(topic == 4)
topicFive <- lincs_top_terms %>% filter(topic == 5)
topicSix <- lincs_top_terms %>% filter(topic == 6)
topicSeven <- lincs_top_terms %>% filter(topic == 7)
topicEight <- lincs_top_terms %>% filter(topic == 8)
topicNine <- lincs_top_terms %>% filter(topic == 9)
topicTen <- lincs_top_terms %>% filter(topic == 10)
topicThree <- lincs_top_terms %>% inner_join(lincsEvents)
topicThree <- lincs_top_terms %>% filter(topic == 3)
topicThree <- topicThree %>% inner_join(lincsEvents)
topicThree <-  topicThree[!duplicated(topicTwo$lincsID), ]
topicThree <-  topicThree[!duplicated(topicThree$lincsID), ]
View(topicThree)
View(topicTen)
topicFour <- topicFour %>% inner_join(lincsEvents)
View(topicThree)
View(lincsEvents)
View(lincsEvents)
lincsEvents)
topicFour <-  topicFour[!duplicated(topicFour$lincsID), ]
View(topicFour)
topicFour <- topicFour %>% inner_join(lincsEvents)
topicFour <-  topicFour[!duplicated(topicFour$lincsID), ]
topicFive <- topicFive %>% inner_join(lincsEvents)
topicFive <-  topicFive[!duplicated(topicFive$lincsID), ]
View(topicFive)
View(topicFive)
topicSix <- topicSix %>% inner_join(lincsEvents)
topicSix <-  topicSix[!duplicated(topicSix$lincsID), ]
topicSeven <- topicSeven %>% inner_join(lincsEvents)
topicSeven <-  topicSeven[!duplicated(topicSeven$lincsID), ]
topicEight <- topicEight %>% inner_join(lincsEvents)
topicEight <-  topicEight[!duplicated(topicEight$lincsID), ]
topicNine <- topicNine %>% inner_join(lincsEvents)
topicNine <-  topicNine[!duplicated(topicNine$lincsID), ]
topicTen <- topicTen %>% inner_join(lincsEvents)
topicTen <-  topicTen[!duplicated(topicTen$lincsID), ]
#Join all the dataframes together
topics <- do.call("rbind", list(topicOne, topicTwo, topicThree, topicFour, topicFive, topicSix, topicSeven, topicEight, topicNine, topicTen))
#I write the result to CSV so I can read it more easily
write.csv(topics, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topics.csv")
View(lincsTopics)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
library(tidyverse)
library(tidytext)
library(broom)
library(reshape2)
#Creates List of top terms that belong to each topic
lincs_top_terms <- lincsTopics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#Visualises the top terms
lincs_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#write.csv(lincs_top_terms, "C:\\Users\\Jack\\Documents\\GitHub\\blog\\Lincolnshire csv Data\\topicModeltop20.csv")
View(lincsEvents)
View(lincsTopics)
View(lincs_top_terms)
View(topicOne)
View(lincsEvents)
View(lincsEventsTokens)
Family <- c(Leah, Laurie, Ellie, Jack)
Family <- c('Leah', 'Laurie', 'Ellie', 'Jack')
Family
