lincsTotalYearWords <- lincsYearWords %>% group_by(lincsID) %>%  summarize(total = sum(n))
lincsYearWords <- full_join(lincsTotalTidy, fullDated, by = 'UUID')
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word.x, day, month, year, date)
lincsYearWords <- lincsYearWords %>% rename(word = word.x)
lincsYearWords <- lincsYearWords %>% count(year, word, sort = TRUE)
lincsTotalYearWords <- lincsYearWords %>% group_by(year) %>%  summarize(total = sum(n))
lincsTotalYearWords <- left_join(lincsYearWords, lincsTotalYearWords)
lincsTotalYearWords
#Remove all rows without a year
lincsTotalYearWords <- na.omit()
#Remove all rows without a year
lincsTotalYearWords <- lincsTotalYearWords %>%  na.omit()
lincsTotalYearWords
lincsTotalYearWords
yearFreqRank <- lincsTotalYearWords %>%  group_by(lincsID) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
freq_by_rank
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincs_tf_idf <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincs_tf_idf
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF
lincsYearTFIDF %>%
select(-total) %>%
arrange(desc(tf_idf))
lincsYearTFIDF
lincsYearTFIDF %>%
select(-total) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
select(-total) %>%
filter(n > 5)
arrange(desc(tf_idf))
---
title: 'Mining a Medieval Court Roll 3: TF-IDF'
author: "Jack Newman"
date: '2020-11-16'
slug: Text Mining
categories: Text Mining
tags:
- Medieval History
- Text Mining
---
Term frequency inverse document frequency (TF-IDF) is both a mouthful and a process often carried out as part of the text mining approach. The primary idea behind TF-IDF is to find the words which are most important for the content of each document by decreasing the weight for commonly used words and increasing the weight for words that are not used very much in a collection as a whole. Essentially it tries to find words that are important (i.e, common) in a text but not ubiquitous. For example, if there were two identical texts with only a single word difference between the two then a tf-idf approach would isolate that single word as the most important when comparing the two texts.
```{r libraries and working dir, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(tidytext)
setwd("C:/Users/Jack/Documents/GitHub/bi-grams")
load(".Rdata")
```
```{r Term Frequency in JUST 1/521, message=FALSE, warning=FALSE}
lincs_words <- Lincolnshire_Tokens %>% count(Lincolnshire_ID, word, sort = TRUE)
total_words <- lincs_words %>% group_by(Lincolnshire_ID) %>%  summarize(total = sum(n))
lincs_words <- left_join(lincs_words, total_words)
lincs_words
```
This creates a table (lincs_words) with one row for each word-allegation combination. `n` is the number of times that work is used in that particular allegation and `total` is the total number of words within that particular allegation. Above you can see the first ten rows from the resulting dataframe.
```{r}
freq_by_rank <- lincs_words %>%  group_by(Lincolnshire_ID) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
freq_by_rank
```
Now I can calculate the frequency of each term across the entire document. This is carried out by dividing `n` - which is the number of times a particular word appears in each allegation - by the total number of times that word appears in the whole court roll. Again, above is a random 10 row selection from the dataframe which results from these calculations.
```{r bind_tf_idf}
lincs_tf_idf <- lincs_words %>% bind_tf_idf(word, Lincolnshire_ID, n)
lincs_tf_idf
```
The tf_idf will be close to zero for the most common words. These are the words which appear in most allegations. From the first ten rows 'of' and 'the' are the lowest. The highest values will be those words which occur in fewer allegations.
```{r}
lincs_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
```
It is unsurprising that almost all of the words which are determined as the most important are place or personal names. A further delving shows that some occupations are also determined as important with 'fletcher' occurring twice and foodstuffs 'pork' and 'poultry'. It may be that the text within each allegation is often too small to adequately characterise using tf-idf. This text is based on a calendared edition. In other words, it has omitted much of the repetitive legalese which predominates in fourteenth century court documents (perhaps all court documents). This aids readability but might hinder analyses such as this one.
```{r stop words, message=FALSE, warning=FALSE}
#Removes entries containing personal names, place names, digits, and common english words.
stop_tf_idf <- lincs_tf_idf %>% anti_join(lincs_stop_people)
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
stop_tf_idf <- stop_tf_idf %>% filter(grepl('^\\D', word))
stop_tf_idf <- stop_tf_idf %>% anti_join(stop_words)
stop_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
```
Removing those words which refer to locations, individuals, or digits (primarily the index create by Bernard McLane the original editor) gives a word list of much more interest. This contains words which indicate a legal process such as 'maintainer' (someone who facilitates lawsuits for third parties to harass others), 'forestaller' (an individual who buys goods in anticipation of rising prices so that they might resell them at a profit.) It also includes words which are indicative of the material involved in the allegations, 'sheep', 'chickens', and professions, 'archer', 'bookbinder', 'oilmaker'. A list like this could be the beginning of a tailored classification which sought to annotate professions, evidence of the possessions of victims of crime, or the prevalence of particular types of judicial processes. I suspect that tf-idf might be even more useful when comparing between larger bodies of text such as between different courts rather than internal comparisons of the sort I have carried out here.
```{r Term Frequency by year in JUST 1/521, message=FALSE, warning=FALSE}
lincsYearWords <- full_join(lincsTotalTidy, fullDated, by = 'UUID')
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word.x, day, month, year, date)
lincsYearWords <- lincsYearWords %>% rename(word = word.x)
lincsYearWords <- lincsYearWords %>% count(year, word, sort = TRUE)
lincsTotalYearWords <- lincsYearWords %>% group_by(year) %>%  summarize(total = sum(n))
lincsTotalYearWords <- left_join(lincsYearWords, lincsTotalYearWords)
#Remove all rows without a year
lincsTotalYearWords <- lincsTotalYearWords %>%  na.omit()
lincsTotalYearWords
```
From this we can see, for example, that more felonies were reported in 1340 than in 1338 or that wool was mentioned more often in 1338 than in other years. Not particularly informative so far. Again `n` is the number of occurences of a word within a year and `total` is the over number of words within each year.
```{r}
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
select(-total) %>%
arrange(desc(tf_idf))
lincsYearTFIDF
```
freq_by_rank <- lincs_words %>%  group_by(Lincolnshire_ID) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
lincs_tf_idf <- lincs_words %>% bind_tf_idf(word, Lincolnshire_ID, n)
lincs_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word.x, day, month, year, date)
lincsYearWords <- full_join(lincsTotalTidy, fullDated, by = 'UUID')
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word.x, day, month, year, date)
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word.x, day, month, year, date)
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word, day, month, year, date)
lincsYearWords <- lincsYearWords %>% rename(word = word.x)
lincsYearWords <- full_join(lincsTotalTidy, fullDated, by = 'UUID')
lincsYearWords <- lincsYearWords %>% select(UUID, lincsID, word, day, month, year, date)
lincsYearWords <- lincsYearWords %>% count(year, word, sort = TRUE)
lincsTotalYearWords <- lincsYearWords %>% group_by(year) %>%  summarize(total = sum(n))
lincsTotalYearWords <- left_join(lincsYearWords, lincsTotalYearWords)
#Remove all rows without a year
lincsTotalYearWords <- lincsTotalYearWords %>%  na.omit()
lincsTotalYearWords
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
select(-total) %>%
arrange(desc(tf_idf))
lincsYearTFIDF
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
select(-total) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
select(-total) %>%
filter(n>5) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
select(-total) %>%
filter(n>10) %>%
arrange(desc(tf_idf))
lincs_tf_idf %>%
select(-total) %>%
filter(n>10) %>%
arrange(desc(tf_idf))
#Removes entries containing personal names, place names, digits, and common english words.
stop_tf_idf <- lincs_tf_idf %>% anti_join(lincs_stop_people)
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
stop_tf_idf <- stop_tf_idf %>% filter(grepl('^\\D', word))
stop_tf_idf <- stop_tf_idf %>% anti_join(stop_words)
stop_tf_idf %>%
select(-total) %>%
filter(n>10) %>%
arrange(desc(tf_idf))
#Removes entries containing personal names, place names, digits, and common english words.
stop_tf_idf <- lincs_tf_idf %>% anti_join(lincs_stop_people)
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
stop_tf_idf <- stop_tf_idf %>% filter(grepl('^\\D', word))
stop_tf_idf <- stop_tf_idf %>% anti_join(stop_words)
stop_tf_idf %>%
select(-total) %>%
filter(n>5) %>%
arrange(desc(tf_idf))
#Removes entries containing personal names, place names, digits, and common english words.
stop_tf_idf <- lincs_tf_idf %>% anti_join(lincs_stop_people)
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
stop_tf_idf <- stop_tf_idf %>% filter(grepl('^\\D', word))
stop_tf_idf <- stop_tf_idf %>% anti_join(stop_words)
stop_tf_idf %>%
select(-total) %>%
filter(n>3) %>%
arrange(desc(tf_idf))
#Removes entries containing personal names, place names, digits, and common english words.
stop_tf_idf <- lincs_tf_idf %>% anti_join(lincs_stop_people)
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
stop_tf_idf <- stop_tf_idf %>% filter(grepl('^\\D', word))
stop_tf_idf <- stop_tf_idf %>% anti_join(stop_words)
stop_tf_idf %>%
select(-total) %>%
#filter(n>3) %>%
arrange(desc(tf))
#Removes entries containing personal names, place names, digits, and common english words.
stop_tf_idf <- lincs_tf_idf %>% anti_join(lincs_stop_people)
stop_tf_idf <- stop_tf_idf %>% anti_join(lincs_stop_places)
stop_tf_idf <- stop_tf_idf %>% filter(grepl('^\\D', word))
stop_tf_idf <- stop_tf_idf %>% anti_join(stop_words)
stop_tf_idf %>%
filter(n>3) %>%
arrange(desc(tf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
filter(n>10) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
filter(n>8) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
filter(total>120) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
filter(n>8) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
filter(n>7) %>%
arrange(desc(tf_idf))
yearFreqRank <- lincsTotalYearWords %>%  group_by(year) %>% mutate(rank = row_number(), 'term frequency' = n/total) %>%  ungroup()
yearFreqRank
lincsYearTFIDF <- lincsTotalYearWords %>% bind_tf_idf(word, year, n)
lincsYearTFIDF %>%
filter(n>8) %>%
arrange(desc(tf_idf))
View(dates1338Count)
View(dates1338Count)
View(lincsEventsTokens)
lincsEventsTokens <- count(word)
library(tidyverse)
library(tidytext)
setwd("C:/Users/Jack/Documents/GitHub/bi-grams")
load(".Rdata")
lincsEventsTokens <- count(word)
lincsEventsTokens <- count(lincsEventsTokens$word)
lincsEventsTokens <- count(word, sort = TRUE)
lincsEventsTokens <- distinct(word)
lincsEventsTokens <- count(word)
#Unstopped plot
lincsEventsTokens %>% count(allegation, sort = TRUE) %>% filter(n > 200) %>% mutate(allegation = reorder(allegation, n)) %>% ggplot(aes(allegation, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Unstopped plot
lincsEventsTokens %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(allegation = reorder(allegation, n)) %>% ggplot(aes(allegation, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Unstopped plot
lincsEventsTokens %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(allegation = reorder(allegation, n)) %>% ggplot(aes(allegation, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Unstopped plot
lincsEventsTokens %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word, n)) %>% ggplot(aes(allegation, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
#Unstopped plot
lincsEventsTokens %>% count(word, sort = TRUE) %>% filter(n > 200) %>% mutate(word = reorder(word, n)) %>% ggplot(aes(word, n)) + geom_col(fill="#ffd700") + xlab(NULL) + coord_flip() + theme_minimal()
wordCounts <- lincsEventsTokens %>% count(word, sort = TRUE) %>% mutate(word = reorder(word, n))
View(wordCounts)
lincsEventsTokens %>% count(word, sort = TRUE)
wordCounts <- lincsTotalTidy %>% count(word, sort = TRUE) %>% mutate(word = reorder(word, n))
View(total_words)
View(lincsTotalTidy)
wordCounts <- lincsTotalTidy %>% count(word, sort = TRUE)
wordCounts <- lincsTotalTidy %>% count(word, sort = TRUE)
wordCounts <- lincsTotalTidy %>% count(word, sort = TRUE)
wordCounts <- wordCounts %>% rename(totalDistinct = n)
inner_join(lincsYearTFIDF, wordCounts, by = word)
view(lincsYearTFIDF)
wordCounts <- wordCounts %>% rename(totalDistinct = n, allegation = word)
#Number of occurrences of each distinct word once names and sums of money are removed
wordCounts <- lincsTotalTidy %>% count(word, sort = TRUE)
wordCounts <- wordCounts %>% rename(totalDistinct = n, allegation = word)
lincsYearTFIDF <- lincsYearTFIDF %>% rename(allegation = word)
inner_join(lincsYearTFIDF, wordCounts, by = word)
inner_join(lincsYearTFIDF, wordCounts, by = allegation)
left_join(lincsYearTFIDF, wordCounts, by = allegation)
TFIDFCounts <- left_join(lincsYearTFIDF, wordCounts, by = allegation)
lincsYearTFIDF <- lincsYearTFIDF %>% rename(allegation = word)
lincsYearTFIDF <- lincsYearTFIDF %>% rename(allegation = 'word')
wordCounts <- wordCounts %>% rename(totalDistinct = n, word = allegation)
wordCounts <- wordCounts %>% rename(word = allegation)
TFIDFCounts <- left_join(lincsYearTFIDF, wordCounts, by = word)
lincsYearTFIDF <- lincsYearTFIDF %>% rename(allegation = 'word')
TFIDFCounts <- left_join(lincsYearTFIDF, wordCounts)
lincsYearTFIDF <- lincsYearTFIDF %>% rename('word' = 'allegation')
wordCounts <- wordCounts %>% rename('word' = 'allegation')
lincsYearTFIDF <- lincsYearTFIDF %>% rename('allegation' = 'word')
wordCounts <- wordCounts %>% rename('allegation' = 'word')
lincsYearTFIDF <- lincsYearTFIDF %>% rename('allegation' = 'word')
lincsYearTFIDF <- lincsYearTFIDF %>% rename('allegation' = word)
View(lincsYearTFIDF)
TFIDFCounts <- left_join(lincsYearTFIDF, wordCounts)
View(TFIDFCounts)
TFIDFCounts %>%
filter(totalDistinct>10) %>%
arrange(desc(tf_idf))
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(allegation %in% monthOrder) %>%
arrange(desc(tf_idf))
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(allegation !%in% monthOrder) %>%
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(allegation %in%! monthOrder) %>%
arrange(desc(tf_idf))
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(allegation %in% monthOrder) %>%
arrange(desc(tf_idf))
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(!(allegation %in% monthOrder)) %>%
arrange(desc(tf_idf))
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(!(allegation %in% monthOrder, allegation == sept)) %>%
monthOrder <- monthOrder %>% bind('sept')
monthOrder <- monthOrder %>% append('sept')
monthOrder
TFIDFCounts %>%
filter(totalDistinct>10) %>%
filter(!(allegation %in% monthOrder)) %>%
arrange(desc(tf_idf))
monthOrder <- monthOrder %>% append('july')
TFIDFCounts %>%
filter(totalDistinct>11) %>%
filter(!(allegation %in% monthOrder)) %>%
arrange(desc(tf_idf))
TFIDFCounts %>%
filter(totalDistinct>20) %>%
filter(!(allegation %in% monthOrder)) %>%
arrange(desc(tf_idf))
monthOrder <- monthOrder %>% append('april')
TFIDFCounts %>%
filter(totalDistinct>20) %>%
filter(!(allegation %in% monthOrder)) %>%
arrange(desc(tf_idf))
#Create `lincsEvents`
lincsOCR <- read_csv("C:/Users/Jack/Documents/GitHub/blog/Lincolnshire csv Data/lincsOCR.csv",  locale = locale(encoding = "latin1"))
library(tidyverse)
library(tidytext)
library(lubridate)
library(spacyr)
library(tif)
library(reticulate)
#Create `lincsEvents`
lincsOCR <- read_csv("C:/Users/Jack/Documents/GitHub/blog/Lincolnshire csv Data/lincsOCR.csv",  locale = locale(encoding = "latin1"))
View(lincsOCR)
#remove any duplicates in lincsOCR
lincsOCR <-  lincsOCR[!duplicated(lincsOCR$UUID), ]
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
#Create `lincsEvents`
lincsOCR <- read_csv("C:/Users/Jack/Documents/GitHub/blog/Lincolnshire csv Data/lincsOCR.csv")
View(lincsEvents)
#remove any duplicates in lincsOCR
lincsOCR <-  lincsOCR[!duplicated(lincsOCR$UUID), ]
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
View(lincsEvents)
lincsEvents <- lincsEvents %>%  select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
#rename column to word for future analysis
lincsEvents <- lincsEvents %>% rename(word = QUOTE_TRANSCRIPTION)
#Delete the first digit from the allegation column. This removes McLane's index.
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
View(lincsEvents)
#Create `lincsEvents`
lincsOCR <- read_csv("C:/Users/Jack/Documents/GitHub/blog/Lincolnshire csv Data/lincsOCR.csv",  locale = locale(encoding = "latin1"))
#remove any duplicates in lincsOCR
lincsOCR <-  lincsOCR[!duplicated(lincsOCR$UUID), ]
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%  select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
#rename column to word for future analysis
lincsEvents <- lincsEvents %>% rename(word = QUOTE_TRANSCRIPTION)
#Delete the first digit from the allegation column. This removes McLane's index.
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word, stringsAsFactors = FALSE)
tif_is_corpus_df(txt)
View(txt)
setdiff(1:1230, txt$doc_id)
setdiff(1:1232, txt$doc_id)
txt[duplicated(txt$doc_id),]
write.csv(txt, "txt.csv")
write.csv(txt, file = "txt.csv")
#Create `lincsEvents`
lincsOCR <- read_csv("C:/Users/Jack/Documents/GitHub/blog/Lincolnshire csv Data/lincsOCR.csv")
#remove any duplicates in lincsOCR
lincsOCR <-  lincsOCR[!duplicated(lincsOCR$UUID), ]
lincsEvents <- filter(lincsOCR, TYPE == 'EVENT')
lincsEvents <- lincsEvents %>%  select(QUOTE_TRANSCRIPTION, UUID)
#Create lincsID to act as index to original print book
lincsEvents <- lincsEvents %>% mutate(lincsID = (str_extract(QUOTE_TRANSCRIPTION, '^\\w+')))
#rename column to word for future analysis
lincsEvents <- lincsEvents %>% rename(word = QUOTE_TRANSCRIPTION)
#Delete the first digit from the allegation column. This removes McLane's index.
lincsEvents <- lincsEvents %>% mutate(word = (str_replace(word, '^\\d+', "")))
View(trigrams_separated)
View(txt)
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word, stringsAsFactors = FALSE)
tif_is_corpus_df(txt)
spacy_initialize()
spacy_finalize()
library(tidyverse)
library(tidytext)
library(lubridate)
library(spacyr)
library(tif)
library(reticulate)
spacy_initialize()
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word, stringsAsFactors = FALSE)
tif_is_corpus_df(txt)
tif_as_corpus_character(txt)
tif_is_corpus_df(txt)
txt <- txt %>% data.frame(doc_id = txt$doc_id, text = txt$text, stringsAsFactors = FALSE)
tif_is_corpus_df(txt)
txtChar <- tif_as_corpus_character(txt)
txtTest <- data.frame(txtChar, stringsAsFactors = FALSE)
View(txtTest)
txtTest <- data.frame(l.apply(txtChar, type.convert), stringsAsFactors = FALSE)
txtTest <- data.frame(lapply(txtChar, type.convert), stringsAsFactors = FALSE)
View(txtTest)
txtTest <- data.frame(as.list(txtChar))
View(txtTest)
txtTest <- data.frame(keyName=names(txtChar), values=txtChar, row.names=NULL)
View(txtTest)
View(txtTest)
txtTest <- enframe(txtChar)
View(txtTest)
tif_is_corpus_df(txtChar)
txt <- txt %>% data.frame(doc_id = lincsEvents$doc_id, text = lincsEvents$text, stringsAsFactors = FALSE)
txt <- txt %>% data.frame(doc_id = lincsEvents$doc_id, text = lincsEvents$text, stringsAsFactors = FALSE)
txt <- txt %>% data.frame(doc_id = lincsEvents$lincsid, text = lincsEvents$word, stringsAsFactors = FALSE)
txt <- txt %>% data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word, stringsAsFactors = FALSE)
tif_is_corpus_df(txt)
library(tif)
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word, stringsAsFactors = FALSE)
tif_is_corpus_df(txt)
parsedTxt <- spacy_parse(txtChar)
txtCorpus <- unlist(txtChar)
View(txtTest)
txt <- txt %>% as.tibble()
tif_is_corpus_df(txt)
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word, stringsAsFactors = FALSE)
View(txt)
tif_is_corpus_df(txt)
txt <- c(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
txt <- lincsEvents %>% data.frame(doc_id = lincsID, text = word)
txt <- lincsEvents %>% data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
tif_is_corpus_df(txt)
View(txt)
View(txt)
View(txt)
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
View(txt)
tif_is_corpus_df(txt)
txt <-  as.data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
txt <- lincsEvents %>%  as.data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
tif_is_corpus_df(txt)
txt <- txt %>% select(doc_id, text)
txt <- lincsEvents %>%  data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
tif_is_corpus_df(txt)
parsedTxt <- spacy_parse(txt)
lincsOCR <-  txt[!duplicated(txt$doc_id), ]
parsedTxt <- spacy_parse(txt)
install.packages("readtext")
ary
library(readtext)
library('readtext')
require(readtext)
require(quanteda)
install.packages("quateda")
install.packages(quanteda)
devtools::install_github("quanteda/readtext")
readtext(paste0(DATA_DIR, "C:/Users/Jack/Documents/GitHub/blog/Lincolnshire csv Data/LincolnshireOCR.csv"), text_field = "QUOTE_TRANSCRIPTION")
install.packages("readtext")
library(tidyverse)
library(tidytext)
library(lubridate)
library(spacyr)
library(tif)
library(reticulate)
#library(quanteda)
spacy_initialize()
txt <- data.frame(doc_id = lincsEvents$lincsID, text = lincsEvents$word)
tif_is_corpus_df(txt)
txt <- data.frame(doc_id = lincsEvents$UUID, text = lincsEvents$word)
tif_is_corpus_df(txt)
parsedTxt <- spacy_parse(txt)
View(parsedTxt)
slice_sample(parsedTxt)
slice_sample(parsedTxt, 10)
slice_sample(parsedTxt, n = 10)
slice_sample(parsedTxt, n = 10)
slice(parsedTxt, 500:510)
